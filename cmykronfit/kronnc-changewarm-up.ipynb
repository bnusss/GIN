{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load train_kronnc.py\n",
    "# random del 15 个nodes  email.txt\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx \n",
    "from networkx.convert import from_dict_of_dicts\n",
    "from networkx.classes.graph import Graph\n",
    "from kronEM import *\n",
    "seed =1900\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "adj_address =\"/data/chenmy/voter/seed1051email128-adjmat.pickle\"\n",
    "with open(adj_address,'rb') as f:\n",
    "    objective_adj = pickle.load(f,encoding='latin1')\n",
    "objective_adj = np.array(objective_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss nodes  tensor([117,  82, 114,  11,  48,  37,  88,  90,  33,  75, 115,  14])\n",
      "miss_edge 2928\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "Ground_truth_adj = torch.FloatTensor(objective_adj)\n",
    "sz = Ground_truth_adj.shape[0]\n",
    "k = int(np.log2(sz))\n",
    "remove_proportion = 0.1\n",
    "del_num = int(sz*remove_proportion)\n",
    "mask_un_obs,mask_obs,miss_idx = missing_label(sz,remove_proportion)\n",
    "G = Ground_truth_adj*mask_obs\n",
    "nG = G.data.numpy()\n",
    "H = G.clone()\n",
    "# print(2,(abs(H.data.numpy()-objective_adj)*mask_obs.data.numpy()).sum())\n",
    "init_z = Ground_truth_adj*mask_un_obs\n",
    "missing_edges = int(init_z.sum())\n",
    "print(\"miss nodes \",miss_idx)\n",
    "# initial partial z with fixed missing edges num\n",
    "z_ele_num = int(mask_un_obs.sum())\n",
    "print(\"miss_edge\",z_ele_num)\n",
    "z_element_choice = torch.randperm(z_ele_num)[:missing_edges]\n",
    "z_element = torch.nonzero(mask_un_obs)\n",
    "init_z_edges = torch.index_select(z_element,0,z_element_choice)\n",
    "H[init_z_edges[:,0],init_z_edges[:,1]] = 1\n",
    "# print(abs((H - Ground_truth_adj)*mask_obs).sum())\n",
    "# print(G,H,z_element_choice)\n",
    "# initial kronecker\n",
    "p0 = torch.FloatTensor([[0.9,0.7],[0.7, 0.3]])#torch.FloatTensor([[0.4408, 0.1770],[0.4951, 0.2585]])  # \n",
    "generator = kronecker_Generator(p0,k,2)\n",
    "Pk = generator.generator_adjacency()\n",
    "init_H = H.data.numpy()\n",
    "label_non_obs = mask_un_obs.data.numpy()\n",
    "init_Pk = Pk.detach().data.numpy()\n",
    "perm = np.arange(sz)\n",
    "print(abs((init_H- objective_adj)*mask_obs.data.numpy()).sum())\n",
    "init_label_non_obs= label_non_obs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective p tensor([[0.9000, 0.7000],\n",
      "        [0.5000, 0.3000]])\n",
      "base tensor(1761.8107)\n",
      "base2 1761.811\n"
     ]
    }
   ],
   "source": [
    "# toy train data  generator\n",
    "# 删除0.25比例的节点 origin: we randomly removed 25% of the nodes and the corresponding edges.\n",
    "k = 7\n",
    "sz = 2**k\n",
    "remove_proportion = 0.1\n",
    "del_num = int(sz*remove_proportion)\n",
    "\n",
    "orip = torch.FloatTensor([[0.9,0.7],[0.5, 0.3]]) # torch.FloatTensor([[0.1981, 0.6427],[0.9684, 0.4522]])  \n",
    "print(\"objective p\", orip)\n",
    "ground_adj = generator_adj(k,orip)\n",
    "\n",
    "Ground_truth_adj_before = (ground_adj>torch.rand((ground_adj.shape))).float()\n",
    "# sigma=Ground_truth_adj\n",
    "\n",
    "\n",
    "\n",
    "baseline = loss_func(Ground_truth_adj_before,ground_adj,1)\n",
    "print(\"base\",baseline)\n",
    "\n",
    "np_baseline = NLL(Ground_truth_adj_before.data.numpy(),ground_adj.data.numpy())\n",
    "print(\"base2\",np_baseline)\n",
    "\n",
    "# shuffle \n",
    "node_num=sz\n",
    "permu_m = torch.eye(node_num)\n",
    "permutetion_arrange = torch.randperm(node_num)\n",
    "permu_m_shuffle= torch.index_select(permu_m,0,permutetion_arrange) \n",
    "\n",
    "Ground_truth_adj = torch.mm(permu_m_shuffle,Ground_truth_adj_before).mm(permu_m_shuffle.t())\n",
    "\n",
    "mask_un_obs,mask_obs,miss_idx = missing_label(sz,remove_proportion)\n",
    "G = Ground_truth_adj*mask_obs\n",
    "init_z = Ground_truth_adj*mask_un_obs\n",
    "missing_edges = int(init_z.sum())\n",
    "\n",
    "# initial partial z with fixed missing edges num\n",
    "z_ele_num = int(mask_un_obs.sum())\n",
    "z_element_choice = torch.randperm(z_ele_num)[:missing_edges]\n",
    "z_element = torch.nonzero(mask_un_obs)\n",
    "init_z_edges = torch.index_select(z_element,0,z_element_choice)\n",
    "H = G.clone()\n",
    "H[init_z_edges[:,0],init_z_edges[:,1]] = 1\n",
    "# print(G,H,z_element_choice)\n",
    "# initial kronecker\n",
    "\n",
    "p0 = torch.rand([2,2])  # torch.FloatTensor([[0.4408, 0.1770],[0.4951, 0.2585]]) \n",
    "generator = kronecker_Generator(p0,k,2)\n",
    "Pk = generator.generator_adjacency()\n",
    "init_H = H.data.numpy()\n",
    "label_non_obs = mask_un_obs.data.numpy()\n",
    "init_Pk = Pk.detach().data.numpy()\n",
    "init_label_non_obs= label_non_obs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel_sample(shape, eps=1e-20):\n",
    "    u = torch.rand(shape)\n",
    "    gumbel = - np.log(- np.log(u + eps) + eps)\n",
    "    if use_cuda:\n",
    "        gumbel = gumbel.cuda()\n",
    "    return gumbel\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "    # gumbel_sample 返回一个sample采样\n",
    "    y = logits + gumbel_sample(logits.size())\n",
    "    return torch.nn.functional.softmax(y/temperature, dim=1)\n",
    "\n",
    "def gumbel_softmax(logits, temperature, hard=False):\n",
    "    \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "    Args:\n",
    "    logits: [batch_size, n_class] unnormalized log-probs\n",
    "    temperature: non-negative scalar\n",
    "    hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "    Returns:\n",
    "    [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "    If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "    be a probabilitiy distribution that sums to 1 across classes\n",
    "    \"\"\"\n",
    "    \n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    \n",
    "    if hard:\n",
    "        k = logits.size()[-1]\n",
    "        y_hard = torch.max(y.data, 1)[1]\n",
    "        y = y_hard\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load kronEM.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import numpy as np\n",
    "\n",
    "def kronecker(A,B):\n",
    "    return torch.einsum(\"ab,cd->acbd\", A, B).view(A.size(0)*B.size(0),  A.size(1)*B.size(1))\n",
    "class kronecker_Generator(nn.Module):\n",
    "    def __init__(self,p0,korder = 3,node_num = 2):\n",
    "        super(kronecker_Generator,self).__init__()\n",
    "        self.p = Parameter(p0,requires_grad = True)\n",
    "        # self.p = Parameter(torch.rand(node_num,node_num,requires_grad=True))\n",
    "        self.korder = korder\n",
    "        # print(self.p)\n",
    "    def generator_adjacency(self):\n",
    "        k = self.korder\n",
    "        p0 = self.p\n",
    "        adj = self.p\n",
    "        for i in range(k-1):\n",
    "            adj = kronecker(adj,p0)\n",
    "        return adj\n",
    "def loss_func(sigma,Pk):\n",
    "    loss = -torch.sum((1-sigma)*torch.log(1-Pk)+sigma*torch.log(Pk))\n",
    "    return loss\n",
    "def metropolis_update_ratio(sigma_before,sigma_later,Pk):\n",
    "    '''\n",
    "    if memory is sufficinet, this one is much cleaner to execute\n",
    "    '''\n",
    "    Nll_before=(1-sigma_before)*np.log(1-Pk) +sigma_before*np.log(Pk)\n",
    "    Nll_later=(1-sigma_later)*np.log(1-Pk) +sigma_later*np.log(Pk)\n",
    "    ratio=np.exp(np.sum(Nll_later-Nll_before))\n",
    "    return ratio\n",
    "def SwapElement(sigma_before,i,j):\n",
    "    i_topology=sigma_before[i,:]\n",
    "    j_topology=sigma_before[j,:]\n",
    "    sigma_later=np.copy(sigma_before)\n",
    "    sigma_later[i,:]=j_topology\n",
    "    sigma_later[j,:]=i_topology\n",
    "    sigma_later[:,i]=sigma_before[:,j]\n",
    "    sigma_later[:,j]=sigma_before[:,i]\n",
    "    sigma_later[i,j]=sigma_before[i,j]\n",
    "    sigma_later[j,i]=sigma_before[j,i]\n",
    "    sigma_later[i,i]=sigma_before[j,j]\n",
    "    sigma_later[j,j]=sigma_before[i,i]\n",
    "    return sigma_later\n",
    "\n",
    "def SamplePermutation(Pk,sigma,u,n1_swap,n2_swap,label_non_obs,obj_adj):\n",
    "    sigma_later=SwapElement(sigma,n1_swap, n2_swap)\n",
    "    ratio=metropolis_update_ratio(sigma,sigma_later,Pk)\n",
    "    if u<ratio:\n",
    "        sigma=sigma_later\n",
    "        label_non_obs=SwapElement(label_non_obs,n1_swap, n2_swap)\n",
    "        obj_adj = SwapElement(obj_adj,n1_swap,n2_swap)\n",
    "#         print(ifswap)\n",
    "    return sigma,label_non_obs,obj_adj\n",
    "def SampleZ(H,Pk,label_non_obs,u):\n",
    "    mat_size=len(Pk)\n",
    "    edge_in_non_obs=(H>0)*label_non_obs  \n",
    "    edge_position=np.where(edge_in_non_obs)\n",
    "    edge_removed=np.random.randint(len(edge_position[0]))\n",
    "    px=Pk[edge_position[0][edge_removed],edge_position[1][edge_removed]]\n",
    "    non_edge_in_non_obs=(H<1)*label_non_obs\n",
    "    ##return \n",
    "    py_array=non_edge_in_non_obs*Pk\n",
    "    py_array=np.ravel(py_array)\n",
    "    py=np.random.choice(range(len(py_array)), size=1, p=py_array/np.sum(py_array))\n",
    "    ratio=(1-py_array[py])/(1-px)\n",
    "    if ratio<u:\n",
    "        H[py//mat_size,py%mat_size]=1\n",
    "        H[edge_position[0][edge_removed],edge_position[1][edge_removed]]=0\n",
    "        # print('accept')\n",
    "    return H\n",
    "\n",
    "def missing_label(sz,missing_percent):\n",
    "     # random sample\n",
    "    missing_num = int(sz*missing_percent)\n",
    "    idx = torch.randperm(sz)[:missing_num]\n",
    "    mask_un_obs = torch.zeros(sz,sz)\n",
    "    for i in idx:\n",
    "        mask_un_obs[i] = 1\n",
    "        mask_un_obs[:,i:i+1] = 1\n",
    "    mask_obs = 1- mask_un_obs\n",
    "    return mask_un_obs,mask_obs,idx\n",
    "# only sigma and kronecker pk are itered\n",
    "def E_step(sigma,N,warmup,Pk,label_non_obs,obj_adj):\n",
    "    u1=np.random.rand(N+warmup)\n",
    "    u2=np.random.rand(N+warmup)\n",
    "    sigma_hist=[]\n",
    "    Z_label=[]\n",
    "    Node_list=np.arange(len(Pk))\n",
    "    element_to_swap=np.random.choice(a=Node_list,size=(2,3*(N+warmup)))\n",
    "    mask=element_to_swap[1,:]!=element_to_swap[0,:]# it is pointless to swap the same element\n",
    "    n1_swap=element_to_swap[0,:][mask]\n",
    "    n2_swap=element_to_swap[1,:][mask]\n",
    "    \n",
    "    for i in range(warmup):\n",
    "        sigma,label_non_obs,obj_adj=SamplePermutation(Pk,sigma,u2[i],n1_swap[i],n2_swap[i],label_non_obs,obj_adj)  \n",
    "    for j in range(warmup):\n",
    "        sigma=SampleZ(sigma,Pk,label_non_obs,u1[i+j:i+j+1]) \n",
    "    for k in range(N):\n",
    "        sigma=SampleZ(sigma,Pk,label_non_obs,u1[i+j+1+k:i+j+1+k+1]) \n",
    "        sigma_hist.append(sigma)\n",
    "    Z_label.append(label_non_obs)\n",
    "    return sigma_hist,Z_label,obj_adj #（H+G）\n",
    "\n",
    "def M_step(epoch,sigma_train,p0,k,N):\n",
    "    losses = []\n",
    "    generator = kronecker_Generator(p0,k,2)\n",
    "    learning_rate = 1e-5#0.0000001\n",
    "    opt_net = optim.SGD(generator.parameters(),lr = learning_rate)\n",
    "    decayRate = 0.95\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=opt_net, gamma=decayRate) \n",
    "    for i in range(epoch):   \n",
    "        opt_net.zero_grad()\n",
    "        Pk = generator.generator_adjacency()\n",
    "        loss = loss_func(sigma_train,Pk,N)\n",
    "        loss2 = loss2_func(sigma_train.detach().numpy(),Pk.detach().numpy(),N)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        # print(str(i),loss.item(),loss2.item(),(loss2-loss).item())\n",
    "        opt_net.step()\n",
    "        scheduler.step()\n",
    "        for group in opt_net.param_groups:\n",
    "            for param in group[\"params\"]: \n",
    "              # print(\"before param\",param)\n",
    "              param.data.clamp_(0.0001,0.9999)\n",
    "              # print(\"after param\",param)\n",
    "    \n",
    "        for p in generator.parameters():\n",
    "            p0 = p.data  \n",
    "        generator = kronecker_Generator(p0,k,2)\n",
    "        Pk = generator.generator_adjacency()\n",
    "        Pk = Pk.detach().numpy() \n",
    "        # evaluation\n",
    "        #   nll infer  nll true\n",
    "    return np.mean(losses),Pk,p0\n",
    "\n",
    "def kronEM(iterstep,N,warmup,H,Pk,label_non_obs,epoch,p0,obj_adj,k):\n",
    "    emlosses = []\n",
    "    for i in range(iterstep):\n",
    "        print(\"start iterstep\",i)\n",
    "        sigma_hist,Z_label,obj_adj = E_step(H,N,warmup,Pk,label_non_obs,obj_adj)\n",
    "        print(\"E-step\")\n",
    "        H = sigma_hist[-1]\n",
    "        label_non_obs = Z_label[-1]\n",
    "        sigma_hist_train = np.array(sigma_hist)\n",
    "        sigma_train = torch.DoubleTensor(sigma_hist_train)\n",
    "        emloss,Pk,p0 = M_step(epoch,sigma_train,p0,k,N)\n",
    "        emlosses.append(emloss)\n",
    "        print(\"*************\\n EM loss is %f\"%emloss,\"p0 is \",p0)\n",
    "        \n",
    "        # evaluation\n",
    "        inferp_nll = NLL(H,Pk)\n",
    "        print(\"inferp_nll is %f \"%(inferp_nll))\n",
    "        obs_mask = (1-label_non_obs).astype(bool)\n",
    "        obs_auc = calauc(obj_adj,Pk,obs_mask)\n",
    "        non_obs_auc = calauc(obj_adj,Pk,label_non_obs.astype(bool))\n",
    "        #         print(\"perm is \", perm)\n",
    "        \n",
    "        label_obs = (1-label_non_obs)\n",
    "        obs_diff_edge = abs((H - obj_adj)*label_obs).sum()\n",
    "        unobs_diff_edge =  abs((H - obj_adj)*label_non_obs).sum()\n",
    "        all_diff_edge = abs((H - obj_adj)).sum()\n",
    "        # D_abs = torch.abs(orip-p0).mean()\n",
    "        print(\"infer p is \",p0,  \"obseved auc  is %f and non_obs auc is %f and obs_diff_edge is %f and un_obs_diff_edge %f and all_diff_edge is %f\"%(obs_auc,non_obs_auc,obs_diff_edge,unobs_diff_edge,all_diff_edge))\n",
    "    \n",
    "    return emlosses,H,Pk\n",
    "\n",
    "def NLL(sigma_true,pk):\n",
    "    Nll_before=(1-sigma_true)*np.log(1-pk) +sigma_true*np.log(pk)\n",
    "    return -np.sum(Nll_before)\n",
    "\n",
    "def loss2_func(sigma_train,Pk,N):\n",
    "    loss2 = 0\n",
    "    for i in range(N):\n",
    "        loss2+= NLL(sigma_train[i],Pk)\n",
    "    # print(loss2)\n",
    "    return loss2/N\n",
    "\n",
    "def loss_func(sigma,Pk,N):\n",
    "    loss = -torch.sum((1-sigma)*torch.log(1-Pk)+sigma*torch.log(Pk))\n",
    "    return loss/N\n",
    "\n",
    "def generator_adj(korder,p):\n",
    "    k = korder\n",
    "    p0 = p\n",
    "    adj = p\n",
    "    for i in range(k-1):\n",
    "        adj = kronecker(adj,p0)\n",
    "    return adj\n",
    "def calauc(H,Pk,mask):\n",
    "    fpr, tpr, thresholds = roc_curve(H[mask],Pk[mask])\n",
    "    Auc = auc(fpr, tpr)\n",
    "    return Auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup=300\n",
    "N = 200\n",
    "iterstep = 50\n",
    "epoch = 20\n",
    "emlosses2,H,pk= kronEM(iterstep,N,warmup,init_H,init_Pk,label_non_obs,epoch,p0,objective_adj,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start iterstep 0\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1880.732760 p0 is  tensor([[0.6497, 0.7507],\n",
      "        [0.6418, 0.3430]])\n",
      "inferp_nll is 1880.726196 \n",
      "infer p is  tensor([[0.6497, 0.7507],\n",
      "        [0.6418, 0.3430]]) obseved auc  is 0.507791 and non_obs auc is 0.555585 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 198.000000 and all_diff_edge is 1416.000000\n",
      "start iterstep 1\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1888.114944 p0 is  tensor([[0.6522, 0.7510],\n",
      "        [0.6402, 0.3417]])\n",
      "inferp_nll is 1888.093872 \n",
      "infer p is  tensor([[0.6522, 0.7510],\n",
      "        [0.6402, 0.3417]]) obseved auc  is 0.441396 and non_obs auc is 0.531746 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 198.000000 and all_diff_edge is 1416.000000\n",
      "start iterstep 2\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1870.849295 p0 is  tensor([[0.6553, 0.7515],\n",
      "        [0.6382, 0.3398]])\n",
      "inferp_nll is 1870.815674 \n",
      "infer p is  tensor([[0.6553, 0.7515],\n",
      "        [0.6382, 0.3398]]) obseved auc  is 0.500678 and non_obs auc is 0.530569 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 198.000000 and all_diff_edge is 1416.000000\n",
      "start iterstep 3\n",
      "E-step\n"
     ]
    }
   ],
   "source": [
    "warmup=3000\n",
    "N = 1500\n",
    "iterstep = 100\n",
    "epoch = 50\n",
    "emlosses2,H,pk= kronEM(iterstep,N,warmup,init_H,init_Pk,label_non_obs,epoch,p0,objective_adj,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start iterstep 0\n",
      "E-step\n",
      "*************\n",
      " EM loss is 2434.850030 p0 is  tensor([[0.4206, 0.6819],\n",
      "        [0.5978, 0.3032]])\n",
      "inferp_nll is 2432.945557 \n",
      "infer p is  tensor([[0.4206, 0.6819],\n",
      "        [0.5978, 0.3032]]) obseved auc  is 0.484402 and non_obs auc is 0.523732 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 198.000000 and all_diff_edge is 1416.000000\n",
      "start iterstep 1\n",
      "E-step\n",
      "*************\n",
      " EM loss is 2336.690232 p0 is  tensor([[0.4334, 0.6890],\n",
      "        [0.6070, 0.3245]])\n",
      "inferp_nll is 2335.270996 \n",
      "infer p is  tensor([[0.4334, 0.6890],\n",
      "        [0.6070, 0.3245]]) obseved auc  is 0.490670 and non_obs auc is 0.534361 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 198.000000 and all_diff_edge is 1416.000000\n",
      "start iterstep 2\n",
      "E-step\n",
      "*************\n",
      " EM loss is 2251.935303 p0 is  tensor([[0.4454, 0.6957],\n",
      "        [0.6153, 0.3417]])\n",
      "inferp_nll is 2250.886230 \n",
      "infer p is  tensor([[0.4454, 0.6957],\n",
      "        [0.6153, 0.3417]]) obseved auc  is 0.486320 and non_obs auc is 0.555070 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 198.000000 and all_diff_edge is 1416.000000\n",
      "start iterstep 3\n",
      "E-step\n",
      "*************\n",
      " EM loss is 2186.923733 p0 is  tensor([[0.4567, 0.7016],\n",
      "        [0.6232, 0.3555]])\n",
      "inferp_nll is 2186.137939 \n",
      "infer p is  tensor([[0.4567, 0.7016],\n",
      "        [0.6232, 0.3555]]) obseved auc  is 0.479646 and non_obs auc is 0.557377 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 198.000000 and all_diff_edge is 1416.000000\n",
      "start iterstep 4\n",
      "E-step\n",
      "*************\n",
      " EM loss is 2129.833539 p0 is  tensor([[0.4660, 0.7073],\n",
      "        [0.6306, 0.3673]])\n",
      "inferp_nll is 2129.241699 \n",
      "infer p is  tensor([[0.4660, 0.7073],\n",
      "        [0.6306, 0.3673]]) obseved auc  is 0.490810 and non_obs auc is 0.560347 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 5\n",
      "E-step\n",
      "*************\n",
      " EM loss is 2098.649065 p0 is  tensor([[0.4746, 0.7123],\n",
      "        [0.6372, 0.3773]])\n",
      "inferp_nll is 2098.191895 \n",
      "infer p is  tensor([[0.4746, 0.7123],\n",
      "        [0.6372, 0.3773]]) obseved auc  is 0.492401 and non_obs auc is 0.556731 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 6\n",
      "E-step\n",
      "*************\n",
      " EM loss is 2072.062247 p0 is  tensor([[0.4826, 0.7170],\n",
      "        [0.6426, 0.3857]])\n",
      "inferp_nll is 2071.712402 \n",
      "infer p is  tensor([[0.4826, 0.7170],\n",
      "        [0.6426, 0.3857]]) obseved auc  is 0.504582 and non_obs auc is 0.551576 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 7\n",
      "E-step\n",
      "*************\n",
      " EM loss is 2054.014987 p0 is  tensor([[0.4896, 0.7212],\n",
      "        [0.6472, 0.3931]])\n",
      "inferp_nll is 2053.747070 \n",
      "infer p is  tensor([[0.4896, 0.7212],\n",
      "        [0.6472, 0.3931]]) obseved auc  is 0.496719 and non_obs auc is 0.551755 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 8\n",
      "E-step\n",
      "*************\n",
      " EM loss is 2040.374819 p0 is  tensor([[0.4964, 0.7248],\n",
      "        [0.6510, 0.3991]])\n",
      "inferp_nll is 2040.169189 \n",
      "infer p is  tensor([[0.4964, 0.7248],\n",
      "        [0.6510, 0.3991]]) obseved auc  is 0.495393 and non_obs auc is 0.560576 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 9\n",
      "E-step\n",
      "*************\n",
      " EM loss is 2027.682558 p0 is  tensor([[0.5022, 0.7281],\n",
      "        [0.6542, 0.4044]])\n",
      "inferp_nll is 2027.528320 \n",
      "infer p is  tensor([[0.5022, 0.7281],\n",
      "        [0.6542, 0.4044]]) obseved auc  is 0.524488 and non_obs auc is 0.538327 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 10\n",
      "E-step\n",
      "*************\n",
      " EM loss is 2008.560206 p0 is  tensor([[0.5079, 0.7310],\n",
      "        [0.6568, 0.4081]])\n",
      "inferp_nll is 2008.444824 \n",
      "infer p is  tensor([[0.5079, 0.7310],\n",
      "        [0.6568, 0.4081]]) obseved auc  is 0.540912 and non_obs auc is 0.547614 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 11\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1999.840894 p0 is  tensor([[0.5131, 0.7334],\n",
      "        [0.6592, 0.4109]])\n",
      "inferp_nll is 1999.753174 \n",
      "infer p is  tensor([[0.5131, 0.7334],\n",
      "        [0.6592, 0.4109]]) obseved auc  is 0.537822 and non_obs auc is 0.536552 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 12\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1992.436922 p0 is  tensor([[0.5182, 0.7355],\n",
      "        [0.6611, 0.4128]])\n",
      "inferp_nll is 1992.366699 \n",
      "infer p is  tensor([[0.5182, 0.7355],\n",
      "        [0.6611, 0.4128]]) obseved auc  is 0.527603 and non_obs auc is 0.523910 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 13\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1992.117880 p0 is  tensor([[0.5228, 0.7370],\n",
      "        [0.6628, 0.4144]])\n",
      "inferp_nll is 1992.062744 \n",
      "infer p is  tensor([[0.5228, 0.7370],\n",
      "        [0.6628, 0.4144]]) obseved auc  is 0.536021 and non_obs auc is 0.525458 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 14\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1989.180587 p0 is  tensor([[0.5271, 0.7382],\n",
      "        [0.6641, 0.4156]])\n",
      "inferp_nll is 1989.137085 \n",
      "infer p is  tensor([[0.5271, 0.7382],\n",
      "        [0.6641, 0.4156]]) obseved auc  is 0.542590 and non_obs auc is 0.522164 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 15\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1987.636388 p0 is  tensor([[0.5310, 0.7391],\n",
      "        [0.6653, 0.4165]])\n",
      "inferp_nll is 1987.601562 \n",
      "infer p is  tensor([[0.5310, 0.7391],\n",
      "        [0.6653, 0.4165]]) obseved auc  is 0.528062 and non_obs auc is 0.553982 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 16\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1982.858687 p0 is  tensor([[0.5344, 0.7399],\n",
      "        [0.6663, 0.4172]])\n",
      "inferp_nll is 1982.832764 \n",
      "infer p is  tensor([[0.5344, 0.7399],\n",
      "        [0.6663, 0.4172]]) obseved auc  is 0.535561 and non_obs auc is 0.542326 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 17\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1978.597919 p0 is  tensor([[0.5376, 0.7406],\n",
      "        [0.6670, 0.4175]])\n",
      "inferp_nll is 1978.576904 \n",
      "infer p is  tensor([[0.5376, 0.7406],\n",
      "        [0.6670, 0.4175]]) obseved auc  is 0.530343 and non_obs auc is 0.535614 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 18\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1978.144179 p0 is  tensor([[0.5407, 0.7410],\n",
      "        [0.6675, 0.4175]])\n",
      "inferp_nll is 1978.125122 \n",
      "infer p is  tensor([[0.5407, 0.7410],\n",
      "        [0.6675, 0.4175]]) obseved auc  is 0.518496 and non_obs auc is 0.531383 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 19\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1978.106355 p0 is  tensor([[0.5436, 0.7414],\n",
      "        [0.6678, 0.4174]])\n",
      "inferp_nll is 1978.089233 \n",
      "infer p is  tensor([[0.5436, 0.7414],\n",
      "        [0.6678, 0.4174]]) obseved auc  is 0.493698 and non_obs auc is 0.546676 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 20\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1976.782035 p0 is  tensor([[0.5466, 0.7416],\n",
      "        [0.6679, 0.4171]])\n",
      "inferp_nll is 1976.764893 \n",
      "infer p is  tensor([[0.5466, 0.7416],\n",
      "        [0.6679, 0.4171]]) obseved auc  is 0.500115 and non_obs auc is 0.538725 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 21\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1971.881996 p0 is  tensor([[0.5493, 0.7417],\n",
      "        [0.6681, 0.4165]])\n",
      "inferp_nll is 1971.865967 \n",
      "infer p is  tensor([[0.5493, 0.7417],\n",
      "        [0.6681, 0.4165]]) obseved auc  is 0.495837 and non_obs auc is 0.527785 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 202.000000 and all_diff_edge is 1420.000000\n",
      "start iterstep 22\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1966.535725 p0 is  tensor([[0.5524, 0.7419],\n",
      "        [0.6679, 0.4154]])\n",
      "inferp_nll is 1966.515259 \n",
      "infer p is  tensor([[0.5524, 0.7419],\n",
      "        [0.6679, 0.4154]]) obseved auc  is 0.495723 and non_obs auc is 0.559368 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 202.000000 and all_diff_edge is 1420.000000\n",
      "start iterstep 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-step\n",
      "*************\n",
      " EM loss is 1964.946328 p0 is  tensor([[0.5551, 0.7421],\n",
      "        [0.6676, 0.4144]])\n",
      "inferp_nll is 1964.929321 \n",
      "infer p is  tensor([[0.5551, 0.7421],\n",
      "        [0.6676, 0.4144]]) obseved auc  is 0.497654 and non_obs auc is 0.551505 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 202.000000 and all_diff_edge is 1420.000000\n",
      "start iterstep 24\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1955.008454 p0 is  tensor([[0.5577, 0.7426],\n",
      "        [0.6671, 0.4130]])\n",
      "inferp_nll is 1954.989990 \n",
      "infer p is  tensor([[0.5577, 0.7426],\n",
      "        [0.6671, 0.4130]]) obseved auc  is 0.501302 and non_obs auc is 0.564280 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 202.000000 and all_diff_edge is 1420.000000\n",
      "start iterstep 25\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1956.048946 p0 is  tensor([[0.5603, 0.7431],\n",
      "        [0.6664, 0.4118]])\n",
      "inferp_nll is 1956.031860 \n",
      "infer p is  tensor([[0.5603, 0.7431],\n",
      "        [0.6664, 0.4118]]) obseved auc  is 0.495791 and non_obs auc is 0.568640 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 202.000000 and all_diff_edge is 1420.000000\n",
      "start iterstep 26\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1956.510343 p0 is  tensor([[0.5622, 0.7436],\n",
      "        [0.6659, 0.4108]])\n",
      "inferp_nll is 1956.499756 \n",
      "infer p is  tensor([[0.5622, 0.7436],\n",
      "        [0.6659, 0.4108]]) obseved auc  is 0.496775 and non_obs auc is 0.576704 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 202.000000 and all_diff_edge is 1420.000000\n",
      "start iterstep 27\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1955.801337 p0 is  tensor([[0.5641, 0.7440],\n",
      "        [0.6654, 0.4098]])\n",
      "inferp_nll is 1955.791992 \n",
      "infer p is  tensor([[0.5641, 0.7440],\n",
      "        [0.6654, 0.4098]]) obseved auc  is 0.501001 and non_obs auc is 0.594739 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 202.000000 and all_diff_edge is 1420.000000\n",
      "start iterstep 28\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1952.224210 p0 is  tensor([[0.5662, 0.7443],\n",
      "        [0.6650, 0.4085]])\n",
      "inferp_nll is 1952.211304 \n",
      "infer p is  tensor([[0.5662, 0.7443],\n",
      "        [0.6650, 0.4085]]) obseved auc  is 0.493228 and non_obs auc is 0.565793 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 202.000000 and all_diff_edge is 1420.000000\n",
      "start iterstep 29\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1955.626320 p0 is  tensor([[0.5682, 0.7445],\n",
      "        [0.6644, 0.4074]])\n",
      "inferp_nll is 1955.615479 \n",
      "infer p is  tensor([[0.5682, 0.7445],\n",
      "        [0.6644, 0.4074]]) obseved auc  is 0.521760 and non_obs auc is 0.503811 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 202.000000 and all_diff_edge is 1420.000000\n",
      "start iterstep 30\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1944.009673 p0 is  tensor([[0.5701, 0.7450],\n",
      "        [0.6639, 0.4058]])\n",
      "inferp_nll is 1943.997070 \n",
      "infer p is  tensor([[0.5701, 0.7450],\n",
      "        [0.6639, 0.4058]]) obseved auc  is 0.522751 and non_obs auc is 0.498659 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 31\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1940.025852 p0 is  tensor([[0.5723, 0.7454],\n",
      "        [0.6634, 0.4040]])\n",
      "inferp_nll is 1940.008789 \n",
      "infer p is  tensor([[0.5723, 0.7454],\n",
      "        [0.6634, 0.4040]]) obseved auc  is 0.532300 and non_obs auc is 0.512014 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 32\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1943.023206 p0 is  tensor([[0.5749, 0.7455],\n",
      "        [0.6628, 0.4021]])\n",
      "inferp_nll is 1943.001465 \n",
      "infer p is  tensor([[0.5749, 0.7455],\n",
      "        [0.6628, 0.4021]]) obseved auc  is 0.542737 and non_obs auc is 0.544373 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 33\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1938.819079 p0 is  tensor([[0.5773, 0.7456],\n",
      "        [0.6623, 0.4002]])\n",
      "inferp_nll is 1938.799438 \n",
      "infer p is  tensor([[0.5773, 0.7456],\n",
      "        [0.6623, 0.4002]]) obseved auc  is 0.544147 and non_obs auc is 0.528597 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 34\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1930.107272 p0 is  tensor([[0.5796, 0.7460],\n",
      "        [0.6618, 0.3980]])\n",
      "inferp_nll is 1930.087280 \n",
      "infer p is  tensor([[0.5796, 0.7460],\n",
      "        [0.6618, 0.3980]]) obseved auc  is 0.540378 and non_obs auc is 0.539634 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 35\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1926.530807 p0 is  tensor([[0.5819, 0.7463],\n",
      "        [0.6614, 0.3958]])\n",
      "inferp_nll is 1926.510010 \n",
      "infer p is  tensor([[0.5819, 0.7463],\n",
      "        [0.6614, 0.3958]]) obseved auc  is 0.532311 and non_obs auc is 0.540458 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 36\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1930.941985 p0 is  tensor([[0.5844, 0.7465],\n",
      "        [0.6608, 0.3937]])\n",
      "inferp_nll is 1930.920654 \n",
      "infer p is  tensor([[0.5844, 0.7465],\n",
      "        [0.6608, 0.3937]]) obseved auc  is 0.524109 and non_obs auc is 0.524753 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 37\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1935.841337 p0 is  tensor([[0.5870, 0.7464],\n",
      "        [0.6603, 0.3918]])\n",
      "inferp_nll is 1935.820312 \n",
      "infer p is  tensor([[0.5870, 0.7464],\n",
      "        [0.6603, 0.3918]]) obseved auc  is 0.520978 and non_obs auc is 0.549094 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 38\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1930.747010 p0 is  tensor([[0.5894, 0.7464],\n",
      "        [0.6599, 0.3898]])\n",
      "inferp_nll is 1930.727173 \n",
      "infer p is  tensor([[0.5894, 0.7464],\n",
      "        [0.6599, 0.3898]]) obseved auc  is 0.521544 and non_obs auc is 0.540052 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 39\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1929.445695 p0 is  tensor([[0.5917, 0.7464],\n",
      "        [0.6596, 0.3879]])\n",
      "inferp_nll is 1929.428345 \n",
      "infer p is  tensor([[0.5917, 0.7464],\n",
      "        [0.6596, 0.3879]]) obseved auc  is 0.518524 and non_obs auc is 0.564650 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 40\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1927.716530 p0 is  tensor([[0.5942, 0.7464],\n",
      "        [0.6591, 0.3859]])\n",
      "inferp_nll is 1927.696045 \n",
      "infer p is  tensor([[0.5942, 0.7464],\n",
      "        [0.6591, 0.3859]]) obseved auc  is 0.520193 and non_obs auc is 0.563437 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 41\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1927.284796 p0 is  tensor([[0.5963, 0.7465],\n",
      "        [0.6587, 0.3841]])\n",
      "inferp_nll is 1927.269287 \n",
      "infer p is  tensor([[0.5963, 0.7465],\n",
      "        [0.6587, 0.3841]]) obseved auc  is 0.521788 and non_obs auc is 0.588100 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 42\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1923.474393 p0 is  tensor([[0.5986, 0.7465],\n",
      "        [0.6583, 0.3822]])\n",
      "inferp_nll is 1923.456421 \n",
      "infer p is  tensor([[0.5986, 0.7465],\n",
      "        [0.6583, 0.3822]]) obseved auc  is 0.519408 and non_obs auc is 0.599533 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 43\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1920.570373 p0 is  tensor([[0.6008, 0.7467],\n",
      "        [0.6579, 0.3802]])\n",
      "inferp_nll is 1920.553223 \n",
      "infer p is  tensor([[0.6008, 0.7467],\n",
      "        [0.6579, 0.3802]]) obseved auc  is 0.514902 and non_obs auc is 0.603292 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 44\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1926.325286 p0 is  tensor([[0.6030, 0.7467],\n",
      "        [0.6573, 0.3786]])\n",
      "inferp_nll is 1926.309448 \n",
      "infer p is  tensor([[0.6030, 0.7467],\n",
      "        [0.6573, 0.3786]]) obseved auc  is 0.513972 and non_obs auc is 0.590015 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 45\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1928.879470 p0 is  tensor([[0.6054, 0.7467],\n",
      "        [0.6566, 0.3771]])\n",
      "inferp_nll is 1928.862427 \n",
      "infer p is  tensor([[0.6054, 0.7467],\n",
      "        [0.6566, 0.3771]]) obseved auc  is 0.513937 and non_obs auc is 0.574828 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-step\n",
      "*************\n",
      " EM loss is 1929.570234 p0 is  tensor([[0.6078, 0.7466],\n",
      "        [0.6558, 0.3756]])\n",
      "inferp_nll is 1929.553101 \n",
      "infer p is  tensor([[0.6078, 0.7466],\n",
      "        [0.6558, 0.3756]]) obseved auc  is 0.521326 and non_obs auc is 0.609262 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 47\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1925.529722 p0 is  tensor([[0.6098, 0.7465],\n",
      "        [0.6553, 0.3742]])\n",
      "inferp_nll is 1925.517456 \n",
      "infer p is  tensor([[0.6098, 0.7465],\n",
      "        [0.6553, 0.3742]]) obseved auc  is 0.523402 and non_obs auc is 0.613968 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 48\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1927.613210 p0 is  tensor([[0.6117, 0.7465],\n",
      "        [0.6548, 0.3729]])\n",
      "inferp_nll is 1927.602539 \n",
      "infer p is  tensor([[0.6117, 0.7465],\n",
      "        [0.6548, 0.3729]]) obseved auc  is 0.510075 and non_obs auc is 0.578106 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 49\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1924.528945 p0 is  tensor([[0.6132, 0.7466],\n",
      "        [0.6545, 0.3717]])\n",
      "inferp_nll is 1924.521118 \n",
      "infer p is  tensor([[0.6132, 0.7466],\n",
      "        [0.6545, 0.3717]]) obseved auc  is 0.516909 and non_obs auc is 0.581700 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 50\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1925.520965 p0 is  tensor([[0.6149, 0.7467],\n",
      "        [0.6540, 0.3705]])\n",
      "inferp_nll is 1925.512207 \n",
      "infer p is  tensor([[0.6149, 0.7467],\n",
      "        [0.6540, 0.3705]]) obseved auc  is 0.514254 and non_obs auc is 0.553383 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 51\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1925.995030 p0 is  tensor([[0.6167, 0.7467],\n",
      "        [0.6535, 0.3694]])\n",
      "inferp_nll is 1925.985352 \n",
      "infer p is  tensor([[0.6167, 0.7467],\n",
      "        [0.6535, 0.3694]]) obseved auc  is 0.519425 and non_obs auc is 0.585096 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 52\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1921.254973 p0 is  tensor([[0.6186, 0.7467],\n",
      "        [0.6530, 0.3680]])\n",
      "inferp_nll is 1921.244141 \n",
      "infer p is  tensor([[0.6186, 0.7467],\n",
      "        [0.6530, 0.3680]]) obseved auc  is 0.522749 and non_obs auc is 0.587925 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 53\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1915.757663 p0 is  tensor([[0.6206, 0.7467],\n",
      "        [0.6524, 0.3665]])\n",
      "inferp_nll is 1915.743652 \n",
      "infer p is  tensor([[0.6206, 0.7467],\n",
      "        [0.6524, 0.3665]]) obseved auc  is 0.520053 and non_obs auc is 0.574490 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 54\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1920.367590 p0 is  tensor([[0.6226, 0.7467],\n",
      "        [0.6517, 0.3652]])\n",
      "inferp_nll is 1920.355957 \n",
      "infer p is  tensor([[0.6226, 0.7467],\n",
      "        [0.6517, 0.3652]]) obseved auc  is 0.520665 and non_obs auc is 0.575194 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 55\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1912.542673 p0 is  tensor([[0.6245, 0.7468],\n",
      "        [0.6511, 0.3637]])\n",
      "inferp_nll is 1912.529785 \n",
      "infer p is  tensor([[0.6245, 0.7468],\n",
      "        [0.6511, 0.3637]]) obseved auc  is 0.520789 and non_obs auc is 0.565090 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 56\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1908.752035 p0 is  tensor([[0.6267, 0.7468],\n",
      "        [0.6505, 0.3620]])\n",
      "inferp_nll is 1908.736816 \n",
      "infer p is  tensor([[0.6267, 0.7468],\n",
      "        [0.6505, 0.3620]]) obseved auc  is 0.519949 and non_obs auc is 0.543663 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 57\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1905.657337 p0 is  tensor([[0.6287, 0.7469],\n",
      "        [0.6499, 0.3603]])\n",
      "inferp_nll is 1905.642944 \n",
      "infer p is  tensor([[0.6287, 0.7469],\n",
      "        [0.6499, 0.3603]]) obseved auc  is 0.518087 and non_obs auc is 0.552083 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 58\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1905.183118 p0 is  tensor([[0.6309, 0.7470],\n",
      "        [0.6493, 0.3587]])\n",
      "inferp_nll is 1905.167725 \n",
      "infer p is  tensor([[0.6309, 0.7470],\n",
      "        [0.6493, 0.3587]]) obseved auc  is 0.526842 and non_obs auc is 0.557578 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 59\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1897.231937 p0 is  tensor([[0.6329, 0.7471],\n",
      "        [0.6488, 0.3568]])\n",
      "inferp_nll is 1897.216309 \n",
      "infer p is  tensor([[0.6329, 0.7471],\n",
      "        [0.6488, 0.3568]]) obseved auc  is 0.528580 and non_obs auc is 0.539927 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 60\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1899.378133 p0 is  tensor([[0.6348, 0.7475],\n",
      "        [0.6481, 0.3552]])\n",
      "inferp_nll is 1899.364746 \n",
      "infer p is  tensor([[0.6348, 0.7475],\n",
      "        [0.6481, 0.3552]]) obseved auc  is 0.531426 and non_obs auc is 0.554278 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 61\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1899.816518 p0 is  tensor([[0.6367, 0.7478],\n",
      "        [0.6474, 0.3537]])\n",
      "inferp_nll is 1899.804199 \n",
      "infer p is  tensor([[0.6367, 0.7478],\n",
      "        [0.6474, 0.3537]]) obseved auc  is 0.544970 and non_obs auc is 0.577408 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 62\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1893.295724 p0 is  tensor([[0.6385, 0.7481],\n",
      "        [0.6467, 0.3520]])\n",
      "inferp_nll is 1893.282104 \n",
      "infer p is  tensor([[0.6385, 0.7481],\n",
      "        [0.6467, 0.3520]]) obseved auc  is 0.537884 and non_obs auc is 0.557113 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 63\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1897.484588 p0 is  tensor([[0.6407, 0.7485],\n",
      "        [0.6457, 0.3506]])\n",
      "inferp_nll is 1897.469116 \n",
      "infer p is  tensor([[0.6407, 0.7485],\n",
      "        [0.6457, 0.3506]]) obseved auc  is 0.542682 and non_obs auc is 0.542386 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 64\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1892.557329 p0 is  tensor([[0.6430, 0.7487],\n",
      "        [0.6446, 0.3490]])\n",
      "inferp_nll is 1892.538574 \n",
      "infer p is  tensor([[0.6430, 0.7487],\n",
      "        [0.6446, 0.3490]]) obseved auc  is 0.541186 and non_obs auc is 0.550978 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 65\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1892.929550 p0 is  tensor([[0.6453, 0.7490],\n",
      "        [0.6435, 0.3475]])\n",
      "inferp_nll is 1892.912598 \n",
      "infer p is  tensor([[0.6453, 0.7490],\n",
      "        [0.6435, 0.3475]]) obseved auc  is 0.544473 and non_obs auc is 0.567370 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 66\n",
      "E-step\n",
      "*************\n",
      " EM loss is 1886.708295 p0 is  tensor([[0.6477, 0.7493],\n",
      "        [0.6424, 0.3458]])\n",
      "inferp_nll is 1886.689209 \n",
      "infer p is  tensor([[0.6477, 0.7493],\n",
      "        [0.6424, 0.3458]]) obseved auc  is 0.546434 and non_obs auc is 0.581066 and obs_diff_edge is 1218.000000 and un_obs_diff_edge 200.000000 and all_diff_edge is 1418.000000\n",
      "start iterstep 67\n",
      "E-step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e95a6edd2570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0miterstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0memlosses2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mkronEM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwarmup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_H\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_Pk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_non_obs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobjective_adj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-048b89a1422e>\u001b[0m in \u001b[0;36mkronEM\u001b[0;34m(iterstep, N, warmup, H, Pk, label_non_obs, epoch, p0, obj_adj, k)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0msigma_hist_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0msigma_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoubleTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_hist_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0memloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0memlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*************\\n EM loss is %f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0memloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"p0 is \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-048b89a1422e>\u001b[0m in \u001b[0;36mM_step\u001b[0;34m(epoch, sigma_train, p0, k, N)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mloss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss2_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# print(str(i),loss.item(),loss2.item(),(loss2-loss).item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch03/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch03/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warmup=30\n",
    "N = 15\n",
    "iterstep = 100\n",
    "epoch = 50\n",
    "emlosses2,H,pk= kronEM(iterstep,N,warmup,init_H,init_Pk,label_non_obs,epoch,p0,objective_adj,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_para =  label_non_obs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kronecker(A,B):\n",
    "    return torch.einsum(\"ab,cd->acbd\", A, B).view(A.size(0)*B.size(0),  A.size(1)*B.size(1))\n",
    "class kronecker_Generator(nn.Module):\n",
    "    def __init__(self,p0,korder = 3,node_num = 2):\n",
    "        super(kronecker_Generator,self).__init__()\n",
    "        self.p = Parameter(p0,requires_grad = True)\n",
    "        # self.p = Parameter(torch.rand(node_num,node_num,requires_grad=True))\n",
    "        self.korder = korder\n",
    "        # print(self.p)\n",
    "    def generator_adjacency(self):\n",
    "        k = self.korder\n",
    "        p0 = self.p\n",
    "        adj = self.p\n",
    "        for i in range(k-1):\n",
    "            adj = kronecker(adj,p0)\n",
    "        return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gumbel_union_kron(nn.Module):\n",
    "    def __init__(self,p0,korder,perm,label_non_obs,temp=10,temp_drop_frac = 0.9999):\n",
    "        super(Gumbel_union_kron).__init__()\n",
    "        self.p = Parameter(p0,requires_grad = True)\n",
    "        self.korder = korder\n",
    "        self.perm = perm\n",
    "        self.label_non_obs = label_non_obs\n",
    "    def generator_adjacency(self):\n",
    "        k = self.korder\n",
    "        p0 = self.p\n",
    "        adj = self.p\n",
    "        for i in range(k-1):\n",
    "            adj = kronecker(adj,p0)\n",
    "        return adj\n",
    "    \n",
    "    def sample_all(self,hard=False):\n",
    "        \n",
    "        self.logp = self.gen_matrix\n",
    "        if use_cuda:\n",
    "            self.logp = self.gen_matrix.cuda()\n",
    "        \n",
    "        out = gumbel_softmax(self.logp, self.temperature, hard)\n",
    "        if hard:\n",
    "            hh = torch.zeros((self.del_num*(2*self.sz - self.del_num-1),2))\n",
    "            for i in range(out.size()[0]):\n",
    "                hh[i, out[i]] = 1\n",
    "            out = hh                    \n",
    "        out = out[:, 0]\n",
    "        if use_cuda:\n",
    "            out = out.cuda()\n",
    "            \n",
    "        matrix = torch.zeros(self.sz,self.sz).cuda()\n",
    "        left_mask = torch.ones(self.sz,self.sz)\n",
    "        left_mask[:-self.del_num,:-self.del_num] = 0\n",
    "        left_mask = left_mask - torch.diag(torch.diag(left_mask))\n",
    "        un_index = left_mask.nonzero()\n",
    "        matrix[(un_index[:,0],un_index[:,1])] = out\n",
    "        out_matrix = matrix\n",
    "        # out_matrix = out[:, 0].view(self.gen_matrix.size()[0], self.gen_matrix.size()[0])\n",
    "        return out_matrix\n",
    "    def init(self, mean, var):\n",
    "        init.normal_(self.gen_matrix, mean=mean, std=var)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''在网络补全任务中生成未知部分结构'''\n",
    "class Gumbel_Generator_nc_asy(nn.Module):\n",
    "    def __init__(self, sz=10,del_num = 1,temp=10, temp_drop_frac=0.9999):\n",
    "        super(Gumbel_Generator_nc_asy, self).__init__()\n",
    "        self.sz = sz\n",
    "        self.del_num = del_num\n",
    "        self.gen_matrix = Parameter(torch.rand(del_num*(2*sz-del_num-1), 2)) #cmy get only unknown part parameter\n",
    "        self.temperature = temp\n",
    "        self.temp_drop_frac = temp_drop_frac\n",
    "\n",
    "    def drop_temp(self):\n",
    "        # 降温过程\n",
    "        self.temperature = self.temperature * self.temp_drop_frac\n",
    "\n",
    "    def sample_all(self, hard=False):\n",
    "        self.logp = self.gen_matrix\n",
    "        if use_cuda:\n",
    "            self.logp = self.gen_matrix.cuda()\n",
    "        \n",
    "        out = gumbel_softmax(self.logp, self.temperature, hard)\n",
    "        if hard:\n",
    "            hh = torch.zeros((self.del_num*(2*self.sz - self.del_num-1),2))\n",
    "            for i in range(out.size()[0]):\n",
    "                hh[i, out[i]] = 1\n",
    "            out = hh                    \n",
    "        out = out[:, 0]\n",
    "        if use_cuda:\n",
    "            out = out.cuda()\n",
    "            \n",
    "        matrix = torch.zeros(self.sz,self.sz).cuda()\n",
    "        left_mask = torch.ones(self.sz,self.sz)\n",
    "        left_mask[:-self.del_num,:-self.del_num] = 0\n",
    "        left_mask = left_mask - torch.diag(torch.diag(left_mask))\n",
    "        un_index = left_mask.nonzero()\n",
    "        matrix[(un_index[:,0],un_index[:,1])] = out\n",
    "        out_matrix = matrix\n",
    "        # out_matrix = out[:, 0].view(self.gen_matrix.size()[0], self.gen_matrix.size()[0])\n",
    "        return out_matrix\n",
    "    def init(self, mean, var):\n",
    "        init.normal_(self.gen_matrix, mean=mean, std=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## union code \n",
    "kronfit 已知部分 + gumbel   + 两个loss （ll+states loss）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(2,size = ([3,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_mat = np.array([0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  85,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  65,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        37,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  22,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_mat  = np.eye(H.shape[0])[perm]\n",
    "shuffle_H = np.dot(np.dot(permutation_mat,objective_adj),permutation_mat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_later1=SwapElement(init_H,37,65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_later=SwapElement(sigma_later,22,85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(sigma_later1-H)*mask_obs.data.numpy()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(shuffle_H-H)*mask_obs.data.numpy()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch03",
   "language": "python",
   "name": "torch03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
